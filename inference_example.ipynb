{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import ipywidgets as ipyw\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchio as tio\n",
    "\n",
    "from utils.utils import get_geodismaps\n",
    "from models.networks import P_RNet3D\n",
    "from data_loaders.transforms import get_transform\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_RNet3D(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv3d(4, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv3d(16, 16, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (block1_downsample): Sequential(\n",
       "    (0): Conv3d(16, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): Conv3d(16, 16, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(2, 2, 0), dilation=(2, 2, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (block2_downsample): Sequential(\n",
       "    (0): Conv3d(16, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4))\n",
       "    (1): ReLU()\n",
       "    (2): Conv3d(16, 16, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(4, 4, 0), dilation=(4, 4, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv3d(16, 16, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(4, 4, 0), dilation=(4, 4, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (block3_downsample): Sequential(\n",
       "    (0): Conv3d(16, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (block4): Sequential(\n",
       "    (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(8, 8, 8), dilation=(8, 8, 8))\n",
       "    (1): ReLU()\n",
       "    (2): Conv3d(16, 16, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(8, 8, 0), dilation=(8, 8, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv3d(16, 16, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(8, 8, 0), dilation=(8, 8, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (block4_downsample): Sequential(\n",
       "    (0): Conv3d(16, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (block5): Sequential(\n",
       "    (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(16, 16, 16), dilation=(16, 16, 16))\n",
       "    (1): ReLU()\n",
       "    (2): Conv3d(16, 16, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(16, 16, 0), dilation=(16, 16, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv3d(16, 16, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(16, 16, 0), dilation=(16, 16, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (block5_downsample): Sequential(\n",
       "    (0): Conv3d(16, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (block6): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Conv3d(20, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Conv3d(16, 2, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnet_best_ckpt_dir = \"./experiments/best_ckpts/brats3d_pnet_init_train\"\n",
    "pnet_best_ckpt_path = sorted(glob.glob(f\"{pnet_best_ckpt_dir}/*.pt\"))[-1]\n",
    "\n",
    "rnet_best_ckpt_dir = \"./experiments/best_ckpts/brats3d_rnet_init_train\"\n",
    "rnet_best_ckpt_path = sorted(glob.glob(f\"{rnet_best_ckpt_dir}/*.pt\"))[-1]\n",
    "\n",
    "pnet = P_RNet3D(c_in=1, c_blk=16, n_classes=2).to(device)\n",
    "rnet = P_RNet3D(c_in=4, c_blk=16, n_classes=2).to(device)\n",
    "\n",
    "pnet.load_state_dict(torch.load(pnet_best_ckpt_path))\n",
    "rnet.load_state_dict(torch.load(rnet_best_ckpt_path))\n",
    "\n",
    "pnet.eval()\n",
    "rnet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on test datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./results\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [05:53<00:00, 17.68s/it]\n"
     ]
    }
   ],
   "source": [
    "test_dir = \"./dataset/test\"\n",
    "test_images = glob.glob(f\"{test_dir}/*/*_flair.nii.gz\")\n",
    "test_labels = glob.glob(f\"{test_dir}/*/*_seg.nii.gz\")\n",
    "\n",
    "test_transform = get_transform(\"valid\")\n",
    "n_classes = 2\n",
    "target_class = 1\n",
    "\n",
    "for image_path, label_path in tqdm(zip(test_images, test_labels), total=len(test_images)):\n",
    "    input_subject = tio.Subject(\n",
    "        image = tio.ScalarImage(image_path),\n",
    "        label = tio.LabelMap(label_path)\n",
    "    )\n",
    "    input_subject = test_transform(input_subject)\n",
    "    inputs = input_subject.image.data.unsqueeze(dim=0).to(device)\n",
    "    true_labels = input_subject.label.data[0, ...].unsqueeze(dim=0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_logits = pnet(inputs)\n",
    "        pred_labels_pnet = torch.argmax(pred_logits, dim=1)\n",
    "        fore_dist_map, back_dist_map = get_geodismaps(inputs, true_labels, pred_labels_pnet)\n",
    "        rnet_inputs = torch.cat([\n",
    "            inputs,\n",
    "            pred_labels_pnet.unsqueeze(dim=1), \n",
    "            torch.Tensor(fore_dist_map).unsqueeze(dim=1).to(device), \n",
    "            torch.Tensor(back_dist_map).unsqueeze(dim=1).to(device)\n",
    "        ], dim=1)\n",
    "\n",
    "        pred_logits = rnet(rnet_inputs)\n",
    "        pred_labels_rnet = torch.argmax(pred_logits, dim=1)\n",
    "\n",
    "        pred_onehot_pnet = torch.nn.functional.one_hot(pred_labels_pnet, n_classes).permute(0, 4, 1, 2, 3)\n",
    "        pred_onehot_target_pnet = pred_onehot_pnet[:, target_class, ...]\n",
    "\n",
    "        pred_onehot_rnet = torch.nn.functional.one_hot(pred_labels_rnet, n_classes).permute(0, 4, 1, 2, 3)\n",
    "        pred_onehot_target_rnet = pred_onehot_rnet[:, target_class, ...]\n",
    "    \n",
    "    pred_labelmap_pnet = tio.LabelMap(\n",
    "        tensor=pred_onehot_target_pnet.cpu(),\n",
    "        affine=input_subject.image.affine\n",
    "    )\n",
    "    pred_labelmap_rnet = tio.LabelMap(\n",
    "        tensor=pred_onehot_target_rnet.cpu(),\n",
    "        affine=input_subject.image.affine\n",
    "    )\n",
    "\n",
    "    save_path_pnet = os.path.join(\n",
    "        save_dir,\n",
    "        os.path.basename(image_path).replace(\"_flair.nii.gz\", \"_pnet_pred.nii.gz\")\n",
    "    )\n",
    "    save_path_rnet = os.path.join(\n",
    "        save_dir,\n",
    "        os.path.basename(image_path).replace(\"_flair.nii.gz\", \"_rnet_pred.nii.gz\")\n",
    "    )\n",
    "\n",
    "    pred_labelmap_pnet.save(save_path_pnet)\n",
    "    pred_labelmap_rnet.save(save_path_rnet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ImageSliceViewer3D_with_prediction:\n",
    "    \n",
    "    # reference = https://github.com/esmitt/imageSliceViewer/blob/master/SliceViewer.ipynb\n",
    "    \n",
    "    \"\"\" \n",
    "    ImageSliceViewer3D is for viewing volumetric image slices in jupyter or\n",
    "    ipython notebooks. \n",
    "    \n",
    "    User can interactively change the slice plane selection for the image and \n",
    "    the slice plane being viewed. \n",
    "\n",
    "    Argumentss:\n",
    "    Volume = 3D input image\n",
    "    figsize = default(8,8), to set the size of the figure\n",
    "    cmap = default('gray'), string for the matplotlib colormap. You can find \n",
    "    more matplotlib colormaps on the following link:\n",
    "    https://matplotlib.org/users/colormaps.html\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image, label, pred_pnet, pred_rnet, overlap = False, figsize=(50,50), cmap_image='gray', cmap_label = 'viridis', cmap_pred_pnet = 'inferno', cmap_pred_rnet = 'magma'):\n",
    "        self.image = image\n",
    "        self.label = label \n",
    "        self.pred_pnet = pred_pnet\n",
    "        self.pred_rnet = pred_rnet\n",
    "        self.figsize = figsize\n",
    "        self.cmap_image = cmap_image\n",
    "        self.cmap_label = cmap_label\n",
    "        self.cmap_pred_pnet = cmap_pred_pnet\n",
    "        self.cmap_pred_rnet = cmap_pred_rnet\n",
    "        self.v = [np.min(image), np.max(image)]\n",
    "        self.v_label = [np.min(label), np.max(label)]\n",
    "        self.v_pred_pnet = [np.min(pred_pnet), np.max(pred_pnet)]\n",
    "        self.v_pred_rnet = [np.min(pred_rnet), np.max(pred_rnet)]\n",
    "        self.overlap = overlap\n",
    "\n",
    "        # Call to select slice plane\n",
    "        ipyw.interact(self.views)\n",
    "    \n",
    "    def views(self):\n",
    "        self.vol1 = np.transpose(self.image, [1,2,0])\n",
    "        self.vol2 = np.rot90(np.transpose(self.image, [2,0,1]), 3) #rotate 270 degrees\n",
    "        self.vol3 = np.transpose(self.image, [0,1,2])\n",
    "        maxZ1 = self.vol1.shape[2] - 1\n",
    "        maxZ2 = self.vol2.shape[2] - 1\n",
    "        maxZ3 = self.vol3.shape[2] - 1\n",
    "        \n",
    "        self.vol1_label = np.transpose(self.label, [1,2,0])\n",
    "        self.vol2_label = np.rot90(np.transpose(self.label, [2,0,1]), 3) #rotate 270 degrees\n",
    "        self.vol3_label = np.transpose(self.label, [0,1,2])\n",
    "        \n",
    "        self.vol1_pred_pnet = np.transpose(self.pred_pnet, [1,2,0])\n",
    "        self.vol2_pred_pnet = np.rot90(np.transpose(self.pred_pnet, [2,0,1]), 3) #rotate 270 degrees\n",
    "        self.vol3_pred_pnet = np.transpose(self.pred_pnet, [0,1,2])\n",
    "        \n",
    "        self.vol1_pred_rnet = np.transpose(self.pred_rnet, [1,2,0])\n",
    "        self.vol2_pred_rnet = np.rot90(np.transpose(self.pred_rnet, [2,0,1]), 3) #rotate 270 degrees\n",
    "        self.vol3_pred_rnet = np.transpose(self.pred_rnet, [0,1,2])\n",
    "        \n",
    "        ipyw.interact(self.plot_slice, \n",
    "            z1=ipyw.IntSlider(min=0, max=maxZ1, step=1, continuous_update=False, \n",
    "            description='Axial:'), \n",
    "            z2=ipyw.IntSlider(min=0, max=maxZ2, step=1, continuous_update=False, \n",
    "            description='Coronal:'),\n",
    "            z3=ipyw.IntSlider(min=0, max=maxZ3, step=1, continuous_update=False, \n",
    "            description='Sagittal:'))\n",
    "\n",
    "    def plot_slice(self, z1, z2, z3):\n",
    "        \n",
    "        if self.overlap:\n",
    "\n",
    "            f, ax = plt.subplots(1,3, figsize=self.figsize)\n",
    "            ax[0].imshow(self.vol1[:,:,z1], cmap=plt.get_cmap(self.cmap_image), \n",
    "                vmin=self.v[0], vmax=self.v[1])\n",
    "            ax[1].imshow(self.vol2[:,:,z2], cmap=plt.get_cmap(self.cmap_image), \n",
    "                vmin=self.v[0], vmax=self.v[1])\n",
    "            ax[2].imshow(self.vol3[:,:,z3], cmap=plt.get_cmap(self.cmap_image), \n",
    "                vmin=self.v[0], vmax=self.v[1])\n",
    "            \n",
    "            ax[0].imshow(self.vol1_label[:,:,z1], cmap=plt.get_cmap(self.cmap_label),\n",
    "                vmin=self.v_label[0], vmax=self.v_label[1], alpha = 0.3)\n",
    "            ax[1].imshow(self.vol2_label[:,:,z2], cmap=plt.get_cmap(self.cmap_label),\n",
    "                vmin=self.v_label[0], vmax=self.v_label[1], alpha = 0.3)\n",
    "            ax[2].imshow(self.vol3_label[:,:,z3], cmap=plt.get_cmap(self.cmap_label),\n",
    "                vmin=self.v_label[0], vmax=self.v_label[1], alpha = 0.3)\n",
    "            \n",
    "            ax[0].imshow(self.vol1_pred_pnet[:,:,z1], cmap=plt.get_cmap(self.cmap_pred_pnet),\n",
    "                vmin=self.v_pred_pnet[0], vmax=self.v_pred_pnet[1], alpha = 0.3)\n",
    "            ax[1].imshow(self.vol2_pred_pnet[:,:,z2], cmap=plt.get_cmap(self.cmap_pred_pnet),\n",
    "                vmin=self.v_pred_pnet[0], vmax=self.v_pred_pnet[1], alpha = 0.3)\n",
    "            ax[2].imshow(self.vol3_pred_pnet[:,:,z3], cmap=plt.get_cmap(self.cmap_pred_pnet),\n",
    "                vmin=self.v_pred_pnet[0], vmax=self.v_pred_pnet[1], alpha = 0.3)\n",
    "\n",
    "            ax[0].imshow(self.vol1_pred_rnet[:,:,z1], cmap=plt.get_cmap(self.cmap_pred_rnet),\n",
    "                vmin=self.v_pred_rnet[0], vmax=self.v_pred_rnet[1], alpha = 0.3)\n",
    "            ax[1].imshow(self.vol2_pred_rnet[:,:,z2], cmap=plt.get_cmap(self.cmap_pred_rnet),\n",
    "                vmin=self.v_pred_rnet[0], vmax=self.v_pred_rnet[1], alpha = 0.3)\n",
    "            ax[2].imshow(self.vol3_pred_rnet[:,:,z3], cmap=plt.get_cmap(self.cmap_pred_rnet),\n",
    "                vmin=self.v_pred_rnet[0], vmax=self.v_pred_rnet[1], alpha = 0.3)\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # default settings: without overlap plots\n",
    "            f, ax = plt.subplots(4,3, figsize=self.figsize)\n",
    "            ax[0][0].imshow(self.vol1[:,:,z1], cmap=plt.get_cmap(self.cmap_image), \n",
    "                vmin=self.v[0], vmax=self.v[1])\n",
    "            ax[0][1].imshow(self.vol2[:,:,z2], cmap=plt.get_cmap(self.cmap_image), \n",
    "                vmin=self.v[0], vmax=self.v[1])\n",
    "            ax[0][2].imshow(self.vol3[:,:,z3], cmap=plt.get_cmap(self.cmap_image), \n",
    "                vmin=self.v[0], vmax=self.v[1])\n",
    "            \n",
    "            ax[1][0].imshow(self.vol1_label[:,:,z1], cmap=plt.get_cmap(self.cmap_label),\n",
    "                vmin=self.v_label[0], vmax=self.v_label[1])\n",
    "            ax[1][1].imshow(self.vol2_label[:,:,z2], cmap=plt.get_cmap(self.cmap_label),\n",
    "                vmin=self.v_label[0], vmax=self.v_label[1])\n",
    "            ax[1][2].imshow(self.vol3_label[:,:,z3], cmap=plt.get_cmap(self.cmap_label),\n",
    "                vmin=self.v_label[0], vmax=self.v_label[1])\n",
    "            \n",
    "            ax[2][0].imshow(self.vol1_pred_pnet[:,:,z1], cmap=plt.get_cmap(self.cmap_pred_pnet),\n",
    "                vmin=self.v_pred_pnet[0], vmax=self.v_pred_pnet[1], alpha = 0.3)\n",
    "            ax[2][1].imshow(self.vol2_pred_pnet[:,:,z2], cmap=plt.get_cmap(self.cmap_pred_pnet),\n",
    "                vmin=self.v_pred_pnet[0], vmax=self.v_pred_pnet[1], alpha = 0.3)\n",
    "            ax[2][2].imshow(self.vol3_pred_pnet[:,:,z3], cmap=plt.get_cmap(self.cmap_pred_pnet),\n",
    "                vmin=self.v_pred_pnet[0], vmax=self.v_pred_pnet[1], alpha = 0.3)\n",
    "\n",
    "            ax[3][0].imshow(self.vol1_pred_rnet[:,:,z1], cmap=plt.get_cmap(self.cmap_pred_rnet),\n",
    "                vmin=self.v_pred_rnet[0], vmax=self.v_pred_rnet[1], alpha = 0.3)\n",
    "            ax[3][1].imshow(self.vol2_pred_rnet[:,:,z2], cmap=plt.get_cmap(self.cmap_pred_rnet),\n",
    "                vmin=self.v_pred_rnet[0], vmax=self.v_pred_rnet[1], alpha = 0.3)\n",
    "            ax[3][2].imshow(self.vol3_pred_rnet[:,:,z3], cmap=plt.get_cmap(self.cmap_pred_rnet),\n",
    "                vmin=self.v_pred_rnet[0], vmax=self.v_pred_rnet[1], alpha = 0.3)\n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed72507b562e4d288d59f321f3096e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Output(),), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ImageSliceViewer3D_with_prediction at 0x7f9e58465f50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnet_inferences = glob.glob(f\"{save_dir}/*_pnet_pred.nii.gz\")\n",
    "rnet_inferences = glob.glob(f\"{save_dir}/*_rnet_pred.nii.gz\")\n",
    "transform = tio.Compose([\n",
    "    tio.ToCanonical(), \n",
    "    tio.Resample(1), \n",
    "    tio.RemapLabels({2:1, 3:1, 4:1})\n",
    "])\n",
    "\n",
    "image_path, label_path, pnet_inf_path, rnet_inf_path = test_images[5], test_labels[5], pnet_inferences[5], rnet_inferences[5]\n",
    "\n",
    "test_subject = tio.Subject(\n",
    "    image = tio.ScalarImage(image_path),\n",
    "    label = tio.LabelMap(label_path),\n",
    "    pnet_inf = tio.LabelMap(pnet_inf_path),\n",
    "    rnet_inf = tio.LabelMap(rnet_inf_path)\n",
    ")\n",
    "test_subject = transform(test_subject)\n",
    "\n",
    "image_np = test_subject.image.data.squeeze(dim=0).numpy()\n",
    "label_np = test_subject.label.data.squeeze(dim=0).numpy()\n",
    "pnet_inf_np = test_subject.pnet_inf.data.squeeze(dim=0).numpy()\n",
    "rnet_inf_np = test_subject.rnet_inf.data.squeeze(dim=0).numpy()\n",
    "\n",
    "ImageSliceViewer3D_with_prediction(image_np, label_np, pnet_inf_np, rnet_inf_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06b312d4da2a9a3686a6d52820f5105a519faf7cd6cc067e3b3e5e11d5973e41"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ys_torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
